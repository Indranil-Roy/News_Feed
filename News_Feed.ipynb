{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "News Feed.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "Cy-H_wccwxER",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import feedparser\n",
        "import requests as rq\n",
        "import tweepy\n",
        "import pandas as pd\n",
        "import textblob\n",
        "\n",
        "\n",
        "consumer_key = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
        "consumer_secret = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
        "access_token = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
        "access_secret = 'xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'\n",
        "\n",
        "auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_secret)\n",
        "\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m2oWxJlc8Nt7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def scrap_news(stock_ticker):\n",
        "  for e in d.entries:\n",
        "    print(e.title)\n",
        "    print(e.published)\n",
        "    print(e.link)\n",
        "    print(e.description)\n",
        "    print(\"\\n\") # 2 newlines\n",
        "\n",
        "def check_sentiment(stock_ticker):\n",
        "  \n",
        "  '''  this function, will check the sentiment for a particular busniess based on the stock ticker '''\n",
        "\n",
        "  \n",
        "\n",
        "  #Extracting Tweets\n",
        "  results = []\n",
        "  search_ticker = '#'+ stock_ticker\n",
        "  for tweet in tweepy.Cursor (api.search, q = search_ticker , lang = \"en\").items(): \n",
        "      results.append(tweet)\n",
        "\n",
        "  #Store tweets data in a data-frame\n",
        "  def tweets_df(results):\n",
        "      id_list = [tweet.id for tweet  in results]\n",
        "      data_set = pd.DataFrame(id_list, columns = [\"id\"])\n",
        "      data_set[\"text\"] = [tweet.text for tweet in results]\n",
        "      data_set[\"created_at\"] = [tweet.created_at for tweet in results]\n",
        "      data_set[\"retweet_count\"] = [tweet.retweet_count for tweet in results]\n",
        "      data_set[\"user_screen_name\"] = [tweet.author.screen_name for tweet in results]\n",
        "      data_set[\"user_followers_count\"] = [tweet.author.followers_count for tweet in results]\n",
        "      data_set[\"user_location\"] = [tweet.author.location for tweet in results]\n",
        "      data_set[\"Hashtags\"] = [tweet.entities.get('hashtags') for tweet in results] \n",
        "      return data_set\n",
        "\t\n",
        "  data_set = tweets_df(results)\n",
        "\n",
        "  #Sentiment checking\n",
        "  text = data_set[\"text\"]\n",
        "  for i in range(0,len(text)):\n",
        "      textB = TextBlob(text[i])\n",
        "      sentiment = textB.sentiment.polarity\n",
        "      data_set.set_value(i, 'Sentiment',sentiment)\n",
        "      if sentiment <0.00:\n",
        "          SentimentClass = 'Negative'\n",
        "          data_set.set_value(i, 'SentimentClass', SentimentClass )\n",
        "      elif sentiment >0.00:\n",
        "          SentimentClass = 'Positive'\n",
        "          data_set.set_value(i, 'SentimentClass', SentimentClass )\n",
        "      else:\n",
        "          SentimentClass = 'Neutral'\n",
        "          data_set.set_value(i, 'SentimentClass', SentimentClass )\n",
        "\n",
        "  text = data_set[\"text\"]\n",
        "  temp = []\n",
        "\n",
        "  #Extracting hash tags\n",
        "  for i in range(0,len(text)):\n",
        "    temp.append ([i for i in text[i].split() if i.startswith(\"#\")])\n",
        "    \n",
        "  data_set['Tags'] = temp\n",
        "  #print(data_set.groupby('SentimentClass')['id'].nunique())\n",
        "  \n",
        "  a = float(data_set.query('SentimentClass == \"Positive\"')['id'].agg('count'))\n",
        "  b = float(data_set.query('SentimentClass == \"Negative\"')['id'].agg('count'))\n",
        "  c = float(data_set.query('SentimentClass == \"Neutral\"')['id'].agg('count'))\n",
        "\n",
        "  print (\"Public opinion for {}: positive {:.2%} Negetive {:.2%} Neutral {:.2%}\") .format(stock_ticker, (a/(a+b+c)), (b/(a+b+c)), (c/(a+b+c)))\n",
        "  print(\"\\n\")\n",
        "  print (\"=================================================================================================\\n\")\n",
        "  \n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
